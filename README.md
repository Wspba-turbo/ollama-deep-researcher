# Ollama Deep Researcher

Ollama Deep Researcher is a fully local web research assistant that uses any LLM hosted by [Ollama](https://ollama.com/search). Give it a topic and it will generate a web search query, gather web search results (via [Tavily](https://www.tavily.com/) by default), summarize the results of web search, reflect on the summary to examine knowledge gaps, generate a new search query to address the gaps, search, and improve the summary for a user-defined number of cycles. It will provide the user a final markdown summary with all sources used. 

![research-rabbit](https://github.com/user-attachments/assets/4308ee9c-abf3-4abb-9d1e-83e7c2c3f187)

Short summary:
<video src="https://github.com/user-attachments/assets/02084902-f067-4658-9683-ff312cab7944" controls></video>

## ğŸ“º Video Tutorials

See it in action or build it yourself? Check out these helpful video tutorials:
- [Overview of Ollama Deep Researcher with R1](https://www.youtube.com/watch?v=sGUjmyfof4Q) - Load and test [DeepSeek R1](https://api-docs.deepseek.com/news/news250120) [distilled models](https://ollama.com/library/deepseek-r1).
- [Building Ollama Deep Researcher from Scratch](https://www.youtube.com/watch?v=XGuTzHoqlj8) - Overview of how this is built.

## ğŸš€ Quickstart

### Mac 

1. Download the Ollama app for Mac [here](https://ollama.com/download).

2. Pull a local LLM from [Ollama](https://ollama.com/search). As an [example](https://ollama.com/library/deepseek-r1:8b): 
```bash
ollama pull deepseek-r1:8b
```

3. For free web search (up to 1000 requests), [sign up for Tavily](https://tavily.com/). 

4. Set the `TAVILY_API_KEY` environment variable and restart your terminal to ensure it is set:

```bash
export TAVILY_API_KEY=<your_tavily_api_key>
```

5. (Recommended) Create a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate
```

6. Clone the repository and launch the assistant with the LangGraph server:

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repository and start the LangGraph server 
git clone https://github.com/langchain-ai/ollama-deep-researcher.git
cd ollama-deep-researcher
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev
```

### Windows 

1. Download the Ollama app for Windows [here](https://ollama.com/download).

2. Pull a local LLM from [Ollama](https://ollama.com/search). As an [example](https://ollama.com/library/deepseek-r1:8b): 
```powershell
ollama pull deepseek-r1:8b
```

3. For free web search (up to 1000 requests), [sign up for Tavily](https://tavily.com/). 

4. Set the `TAVILY_API_KEY` environment variable in Windows (via System Properties or PowerShell). Crucially, restart your terminal/IDE (or sometimes even your computer) after setting it for the change to take effect.

5. (Recommended) Create a virtual environment: Install `Python 3.11` (and add to PATH during installation). Restart your terminal to ensure Python is available, then create and activate a virtual environment:

```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

6. Clone the repository and launch the assistant with the LangGraph server:

```powershell
# Clone the repository 
git clone https://github.com/langchain-ai/ollama-deep-researcher.git
cd ollama-deep-researcher

# Install dependencies 
pip install -e .
pip install langgraph-cli[inmem]

# Start the LangGraph server
langgraph dev
```

## ä½¿ç”¨æŠ€æœ¯å…¨æ™¯å›¾ç”ŸæˆåŠŸèƒ½

ä½ å¯ä»¥ä½¿ç”¨ `generate_tech_landscape.py` è„šæœ¬æ¥ç”ŸæˆæŠ€æœ¯å…¨æ™¯å›¾ã€‚è¯¥è„šæœ¬ä¼šå¯¹æŒ‡å®šçš„æŠ€æœ¯è¿›è¡Œæ·±å…¥åˆ†æï¼Œç”Ÿæˆç›¸å…³æŠ€æœ¯çš„æ ‘çŠ¶å›¾ï¼Œå¹¶æä¾›å¯è§†åŒ–ç»“æœã€‚

### åŸºæœ¬ç”¨æ³•

```bash
python generate_tech_landscape.py <æŠ€æœ¯åç§°> [é€‰é¡¹]
```

### å‚æ•°è¯´æ˜

- `æŠ€æœ¯åç§°`: è¦åˆ†æçš„æ ¹æŠ€æœ¯åç§°
- `--output`, `-o`: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼štech_landscape.jsonï¼‰
- `--depth`, `-d`: æŠ€æœ¯æ ‘çš„æœ€å¤§æ·±åº¦ï¼ˆé»˜è®¤ï¼š2ï¼‰
- `--max-related`, `-m`: æ¯ä¸ªèŠ‚ç‚¹çš„ç›¸å…³æŠ€æœ¯æ•°é‡ä¸Šé™ï¼ˆé»˜è®¤ï¼š5ï¼‰
- `--language`, `-l`: è¾“å‡ºè¯­è¨€ï¼ˆé»˜è®¤ï¼šEnglishï¼‰
- `--model`: ä½¿ç”¨çš„ Ollama æ¨¡å‹ï¼ˆé»˜è®¤ï¼šmistralï¼‰
- `--iterations`, `-i`: æ¯ä¸ªæŠ€æœ¯çš„ç ”ç©¶è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š2ï¼‰

### ç¤ºä¾‹

1. åŸºæœ¬ä½¿ç”¨ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰ï¼š
```bash
python generate_tech_landscape.py "AI Agent"
```

2. æŒ‡å®šå‚æ•°ï¼š
```bash
python generate_tech_landscape.py "AI Agent" -d 1 -m 3 -l "English" --model mistral --iterations 2
```

### è¾“å‡ºæ–‡ä»¶

è„šæœ¬ä¼šç”Ÿæˆä¸¤ä¸ªè¾“å‡ºæ–‡ä»¶ï¼š
1. JSON æ–‡ä»¶ï¼ˆé»˜è®¤ï¼štech_landscape.jsonï¼‰ï¼šåŒ…å«å®Œæ•´çš„æŠ€æœ¯åˆ†æç»“æœï¼ŒåŒ…æ‹¬ï¼š
   - æŠ€æœ¯åç§°
   - æŠ€æœ¯æè¿°
   - æ·±åº¦çº§åˆ«
   - å†å²æ€»ç»“
   - ç›¸å…³æŠ€æœ¯åˆ—è¡¨

2. å¯è§†åŒ–æ–‡ä»¶ï¼š
   - äº¤äº’å¼ HTML å›¾ï¼ˆä¾‹å¦‚ï¼šai_agent_landscape.htmlï¼‰
     * æ”¯æŒç¼©æ”¾å’Œæ‹–åŠ¨
     * èŠ‚ç‚¹é¢œè‰²æ ¹æ®æ·±åº¦å˜åŒ–
     * é¼ æ ‡æ‚¬åœæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
     * å¯è°ƒæ•´ç‰©ç†å¸ƒå±€å‚æ•°
   
   - é™æ€ PNG å›¾ï¼ˆä¾‹å¦‚ï¼šai_agent_landscape.pngï¼‰
     * ä»¥èŠ‚ç‚¹å’Œè¾¹å±•ç¤ºæŠ€æœ¯ä¹‹é—´çš„å…³ç³»
     * ä½¿ç”¨ä¸åŒçš„é¢œè‰²å’Œå¤§å°æ¥è¡¨ç¤ºæŠ€æœ¯çš„å±‚çº§
     * æ¸…æ™°å±•ç¤ºæŠ€æœ¯ä¹‹é—´çš„å…³è”æ€§

### æ–°åŠŸèƒ½äº®ç‚¹

- **å¾ªç¯æ£€æµ‹**ï¼šé¿å…é‡å¤åˆ†æç›¸åŒæŠ€æœ¯
- **åŠ¨æ€æœç´¢ä¼˜åŒ–**ï¼šå±‚çº§è¶Šæ·±ï¼Œæœç´¢ç»“æœè¶Šç²¾ç®€
- **äº¤äº’å¼å¯è§†åŒ–**ï¼šæ›´ç›´è§‚åœ°æ¢ç´¢æŠ€æœ¯å…³ç³»
- **æ€§èƒ½ä¼˜åŒ–**ï¼šä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤æœç´¢
- **é”™è¯¯æ¢å¤æœºåˆ¶**ï¼š
  * APIé…é¢ç”¨å°½æ—¶è‡ªåŠ¨ä¿å­˜å·²å®Œæˆçš„åˆ†æç»“æœ
  * ç”Ÿæˆéƒ¨åˆ†ç»“æœæ–‡ä»¶ï¼ˆ`partial_results_*.json`ï¼‰
  * ä¿å­˜åˆ†æè¿›åº¦å’Œå·²å®Œæˆçš„æŠ€æœ¯èŠ‚ç‚¹
- **æŠ€æœ¯é»‘åå•è¿‡æ»¤**ï¼š
  * è¿‡æ»¤è¿‡äºå®½æ³›çš„æœ¯è¯­ï¼ˆå¦‚"machine learning", "AI"ç­‰ï¼‰
  * ç¡®ä¿æå–å…·ä½“çš„æŠ€æœ¯å®ç°å’Œå·¥å…·
  * æé«˜æŠ€æœ¯å…³è”çš„ç²¾ç¡®åº¦
- **å…³ç³»å¼ºåº¦ä¼˜åŒ–**ï¼š
  * æ›´ç²¾ç¡®çš„æŠ€æœ¯å…³è”åº¦è®¡ç®—
  * ä¼˜åŒ–èŠ‚ç‚¹å¤§å°å’Œè¾¹çš„æ ·å¼
  * æ¸…æ™°å±•ç¤ºæŠ€æœ¯ä¹‹é—´çš„å…³è”ç¨‹åº¦

### é”™è¯¯å¤„ç†å’Œæ¢å¤

å½“åˆ†æè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼ˆå¦‚APIé…é¢ç”¨å°½ï¼‰æ—¶ï¼Œç³»ç»Ÿä¼šï¼š

1. è‡ªåŠ¨ä¿å­˜å·²å®Œæˆçš„åˆ†æç»“æœ
2. ç”Ÿæˆéƒ¨åˆ†ç»“æœæ–‡ä»¶ï¼ˆ`partial_results_*.json`ï¼‰ï¼ŒåŒ…å«ï¼š
   - å·²åˆ†æçš„æŠ€æœ¯èŠ‚ç‚¹
   - åˆ†ææ—¶é—´æˆ³
   - å®Œæˆåº¦ä¿¡æ¯
   - å·²å»ºç«‹çš„æŠ€æœ¯å…³ç³»
3. ç»§ç»­ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶ï¼ˆåŸºäºå·²æœ‰æ•°æ®ï¼‰
4. åœ¨æ—¥å¿—ä¸­è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæ¢å¤è¿‡ç¨‹

è¿™äº›æœºåˆ¶ç¡®ä¿å³ä½¿åœ¨å‡ºé”™æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½ä¿ç•™æœ‰ä»·å€¼çš„åˆ†æç»“æœï¼Œä¸ä¼šä¸¢å¤±å·²å®Œæˆçš„å·¥ä½œã€‚

## How it works

[Original content continues below...]

[Previous content remains unchanged]
